# Read This Before Editing Data

This file contains specifics for organizing and editing data. Please read it carefully as this is very important for creating good models.


### Data Guidelines

1. NER

- Compile as many sentences as possible containing identifiable entities.
- As long as the sentences are coherent and we compile some from every possible intent, it is hard to mess this up with sloppy data.

2. Intent

- ***YOU MUST LOOK THROUGH EVERY SENTENCE PUT INTO THE INTENT MODEL***. Don't just generate 150 sentences and call it good without checking them for the below properties.
- If you put data into one intent that could also go into another one, you must give it both labels. For example, prompted-name sentences should go into all of the reservation and order intents.
  - The best way to do this is to create a file that encompasses the action which should go into multiple intents, and store that in the multi-intent folder.
- Do not input wacky sentences generated by a LLM that nobody will ever say, the odd language and extra words can fuck up the model.
- However, broken English sentences are very good for training. These tend to not fuck with the model and help it to understand the general notion of the intent.


----
### Organization

I am going to go through each folder and its purpose.



1. processing

- This folder stores all Python files used for processing the data.
- processing.py contains functions to write out data into the necessary format for both intent and NER models
- data_helper_functions.py contains every other function we use to process data.
  - For example, deleting duplicates, or removing any line with a specific phrase.
  - If you ever need something like this done, please check for the necessary function within the file first. If it is not there, create your own function and provide an explanation of it for others to use.



2. Intent

- This folder contains all data relating exclusively to the Intent model(s).
- The folder contains many sub-folders, each relating to a meaningful grouping of intents, easily decipherable based on the names. Each of these sub-folders should contain finalized outputs and base datasets.
- The Multi-Intent folder should contain .txt files that should go into more than one intent. Make sure to use a name for these files that is easy to understand.
- There is also a Final-Datasets sub-folder. This should contain only the completely finalized .txt and formatted dataset for the intent model(s)



3. NER

- This folder is very similar to the Intent folder. It contains multiple folders relating to meaningful groupings of NER data.
- Each Order and Reservation folder should contain finished data relating to the NER for these groupings.
- Filler-Data holds files with filler data for dynamic sentences, our processing files will automatically insert random lines from these files into empty labels in dynamic sentences.
- This also contains a Final-Datasets sub-folder.




4. Order-Specifics and Reservation-Specifics

- These two folders are very similar. They contain data that is specific to each pipeline and sectioned into meaningful groupings.
  - It is very helpful to keep data separated into files such as prompted inputs and separate intents, then combine the data when you are compiling for a new model.



### Compiling Data For a New Model

- Creating and organizing data is important, but if you mess up compiling it, none of that matters. Pay very close attention to what you are doing, be sure to remember the data guidelines outlined in the initial section of this file.
- Find all data from separated files throughout the specific folders and the model type folder, bring all the data into Final.txt, and send it through processing.py to convert it into a usable format. You can store both the Final.txt and outputted useable data in the Final-Datasets folder of the model type.



---

That's the end for now. If you have any questions please bring it up to me(Travis) as soon as possible and I can amend the document.

Again, **this is very important**. Unorganized data will lead to more sloppy models, wasted time, and wasted money. 
