{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JERTmate data processing\n",
    "\n",
    "#### Compiling Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_files = {\n",
    "    # miscellaneous\n",
    "    \"greetingSingle\": \"../Misc/greeting.txt\",\n",
    "    \"greetingMultiple\": \"../Misc/greetingMultiIntent.txt\",\n",
    "    \"farewell\": \"../Misc/farewell.txt\",\n",
    "    \"out_of_scope\": \"../Misc/Out_of_Scope/out_of_scope.txt\",\n",
    "    \"prompted_name\": \"../Misc/Prompted_Name/prompted_name.txt\",\n",
    "    \"confirm\": \"../Misc/confirm.txt\",\n",
    "    \"deny\": \"../Misc/deny.txt\",\n",
    "    \"allergy_declaration\": '../Misc/allergy_declaration.txt',\n",
    "\n",
    "    # reservation\n",
    "    \"cancel_res\": \"../Reservation/cancel_res.txt\",\n",
    "    \"view_res\": \"../Reservation/view_res.txt\",\n",
    "    \"change_res_info\": \"../Reservation/change_res_info.txt\",\n",
    "    \"add_res_info\": \"../Reservation/add_res_info.txt\",\n",
    "    \"prompted_res_inputs\": \"../Reservation/prompted_res_inputs.txt\",\n",
    "    \n",
    "    # order\n",
    "    \"add_order_info\": \"../Order/manage_order_info/add_order_info.txt\",\n",
    "    \"delete_order_info\": \"../Order/manage_order_info/delete_order_info.txt\",\n",
    "    \"prompted_add_info\": \"../Order/manage_order_info/prompted_add_info.txt\",\n",
    "    \"swap_order_info\": \"../Order/manage_order_info/swap_order_info.txt\",\n",
    "    \"access_prev_order\": \"../Order/access_prev_order.txt\",\n",
    "    \"view_order\": \"../Order/view_order.txt\",\n",
    "    \"cancel_order\": \"../Order/cancel_order.txt\",\n",
    "    \"checkout\": \"../Order/checkout.txt\",\n",
    "    \"create_order\": \"../Order/create_order.txt\",\n",
    "\n",
    "    # inquiry\n",
    "    'allergen_inquiry': \"../Inquiry/allergen_inquiry.txt\", \n",
    "    'basic_inquiry': \"../Inquiry/basic_inquiry.txt\", \n",
    "    'hours_inquiry': \"../Inquiry/hours_inquiry.txt\", \n",
    "    'language_inquiry': \"../Inquiry/language_inquiry.txt\", \n",
    "    'location_inquiry': \"../Inquiry/location_inquiry.txt\", \n",
    "    'manager_inquiry': \"../Inquiry/manager_inquiry.txt\", \n",
    "    'object_description_inquiry': \"../Inquiry/object_description_inquiry.txt\", \n",
    "    'object_ingredient_inquiry': \"../Inquiry/object_ingredient_inquiry.txt\", \n",
    "    'object_nutritional_inquiry': \"../Inquiry/object_nutritional_inquiry.txt\", \n",
    "    'object_recommendation_inquiry': \"../Inquiry/object_recommendation_inquiry.txt\", \n",
    "    'order_queue_inquiry': \"../Inquiry/order_queue_inquiry.txt\", \n",
    "    'possible_object_inquiry': \"../Inquiry/possible_object_inquiry.txt\", \n",
    "    'possible_order_inquiry': \"../Inquiry/possible_order_inquiry.txt\", \n",
    "    'possible_reservation_inquiry': \"../Inquiry/possible_reservation_inquiry.txt\", \n",
    "    'price_inquiry': \"../Inquiry/price_inquiry.txt\", \n",
    "    'profile_inquiry': \"../Inquiry/profile_inquiry.txt\", \n",
    "    'repeat_inquiry': \"../Inquiry/repeat_inquiry.txt\", \n",
    "    'sms_inquiry': \"../Inquiry/sms_inquiry.txt\", \n",
    "    'software_inquiry': \"../Inquiry/software_inquiry.txt\", \n",
    "    'table_queue_inquiry': \"../Inquiry/table_queue_inquiry.txt\", \n",
    "    'volume_inquiry': \"../Inquiry/volume_inquiry.txt\",\n",
    "}\n",
    "\n",
    "inquiry_intents = ['allergen_inquiry', 'basic_inquiry', 'hours_inquiry', 'language_inquiry', 'location_inquiry', 'manager_inquiry', 'object_description_inquiry', 'object_ingredient_inquiry', 'object_nutritional_inquiry', 'object_recommendation_inquiry', 'order_queue_inquiry', 'possible_object_inquiry', 'possible_order_inquiry', 'possible_reservation_inquiry', 'price_inquiry', 'profile_inquiry', 'repeat_inquiry', 'sms_inquiry', 'software_inquiry', 'table_queue_inquiry', 'volume_inquiry']\n",
    "\n",
    "reservation_slots = ['NAME', 'DATE', 'TIME', 'NUMBER']\n",
    "\n",
    "# Shared storage objects to store found arrays of sentences\n",
    "storage = {}\n",
    "storage_copy = {}\n",
    "\n",
    "for intent, file_path in sentence_files.items():\n",
    "    with open(file_path, 'r') as file:\n",
    "        storage[intent] = [line.strip() for line in file.readlines() if line.strip() and not line.strip().startswith(\"//\")]\n",
    "\n",
    "storage_copy = copy.deepcopy(storage)\n",
    "\n",
    "def get_random_line(intent):\n",
    "    if len(storage[intent]) == 0:\n",
    "        storage[intent] = storage_copy[intent].copy()\n",
    "        \n",
    "    selected_entity = random.choice(storage[intent]).strip()\n",
    "    storage[intent].remove(selected_entity)\n",
    "    return selected_entity\n",
    "\n",
    "def process_sentence(sentence, intent):\n",
    "    sentence = sentence.split(':')\n",
    "    if len(sentence) == 1:\n",
    "        return '|' + intent + ':' + sentence[0]\n",
    "    elif len(sentence) == 2:\n",
    "        if '[' in sentence[0]:\n",
    "            sentence[0] = sentence[0].replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "            return '|' + intent + ',' + sentence[0] + ':' + sentence[1]\n",
    "        else:\n",
    "            return '|' + sentence[0] + ':' + sentence[1]\n",
    "    elif len(sentence) == 3:\n",
    "        sentence[1] = sentence[1].replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        return '|' + sentence[0] + ',' + sentence[1] + ':' + sentence[1]\n",
    "\n",
    "def process_line(line, intent):\n",
    "    output = ''\n",
    "    line = line.split('|')\n",
    "    for sentence in line:\n",
    "        output += process_sentence(sentence, intent)\n",
    "\n",
    "    return output\n",
    "\n",
    "def randomize_greeting():\n",
    "    if random.random() < 0.7:\n",
    "        if random.random() < 0.2:\n",
    "            return process_line(get_random_line(\"greetingMultiple\"), 'greeting')\n",
    "        else:\n",
    "            return process_line(get_random_line(\"greetingSingle\"), 'greeting')\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def randomize_farewell():\n",
    "    if random.random() < 0.7:\n",
    "        return process_line(get_random_line(\"farewell\"), 'farewell')\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def randomize_oos():\n",
    "    if random.random() < 0.007:\n",
    "        return '|out_of_scope:' + get_random_line(\"out_of_scope\")\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def randomize_inquiry():\n",
    "    intent = random.choice(inquiry_intents)\n",
    "    return process_line(get_random_line(intent), intent)\n",
    "    \n",
    "def compile_inquiry_sentences():\n",
    "    conversation = ''\n",
    "\n",
    "    # define chances\n",
    "    new_sentence_chances = [1, 0.5, 0.15, 0.5, 0]\n",
    "\n",
    "    # order content\n",
    "    sentence_count = 0\n",
    "    while random.random() < new_sentence_chances[min(sentence_count, len(new_sentence_chances) - 1)]:\n",
    "        sentence_count += 1\n",
    "        conversation += randomize_oos()\n",
    "        conversation += randomize_inquiry()\n",
    "\n",
    "    return conversation\n",
    "\n",
    "def compile_reservation_sentences():\n",
    "    conversation = ''\n",
    "\n",
    "    # define chances\n",
    "    sentence_type_chances = {\n",
    "        \"add_res_info\": [0.79, 0.05],\n",
    "        \"prompted_res_inputs\": [0, 0.74],\n",
    "        \"cancel_res\": [0.05],\n",
    "        \"view_res\": [0.05],\n",
    "        \"change_res_info\": [0.05],\n",
    "        \"inquiry\": [0.02],\n",
    "        \"confirm\": [0.02],\n",
    "        \"deny\": [0.02]\n",
    "    }\n",
    "    new_sentence_chances = [1, 0.9, 0.9, 0.8, 0.3, 0.5, 0]\n",
    "\n",
    "    # order content\n",
    "    sentence_count = 0\n",
    "    while random.random() < new_sentence_chances[min(sentence_count, len(new_sentence_chances) - 1)]:\n",
    "        conversation += randomize_oos()\n",
    "\n",
    "        # select intent with specified chances\n",
    "        selected_intent = ''\n",
    "        rand = random.random()\n",
    "        chance_counter = 0\n",
    "        for key, value in sentence_type_chances.items():\n",
    "            chance_counter += value[min(sentence_count, len(value) - 1)]\n",
    "            if rand < chance_counter:\n",
    "                selected_intent = key\n",
    "                break\n",
    "\n",
    "        if selected_intent == 'prompted_res_inputs':\n",
    "            if random.random() < 0.4:\n",
    "                slot = random.choice(reservation_slots)\n",
    "                conversation += '|add_res_info:' + slot + \",0,0,0\"\n",
    "            else:\n",
    "                conversation += process_line(get_random_line(\"prompted_res_inputs\"), 'add_res_info')\n",
    "        elif selected_intent == 'inquiry':\n",
    "            conversation += randomize_inquiry()\n",
    "        else:\n",
    "            conversation += process_line(get_random_line(selected_intent), selected_intent)\n",
    "\n",
    "        sentence_count += 1\n",
    "\n",
    "    return conversation\n",
    "\n",
    "\n",
    "def compile_order_sentences():\n",
    "    conversation = ''\n",
    "\n",
    "    # define chances\n",
    "    sentence_type_chances = {\n",
    "        \"create_order\": [0.4, 0.04, 0.04, 0.03, 0.03, 0.02, 0.02, 0.01],\n",
    "        \"access_prev_order\": [0.32, 0.04, 0.04, 0.03, 0.03, 0.02, 0.02, 0.01],\n",
    "        \"add_order_info\": [0.05, 0.37, 0.29, 0.26, 0.25, 0.20, 0.18, 0.15],\n",
    "        \"prompted_add_info\": [0, 0.29, 0.3, 0.30, 0.26, 0.28, 0.2, 0.15],\n",
    "        \"swap_order_info\": [0.04],\n",
    "        \"delete_order_info\": [0.03],\n",
    "        \"cancel_order\": [0.04],\n",
    "        \"view_order\": [0.04, 0.04, 0.05, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "        \"checkout\": [0.01, 0.04, 0.1, 0.1, 0.15, 0.2, 0.3, 0.4],\n",
    "\n",
    "        \"allergy_declaration\": [0.01],\n",
    "        \"inquiry\": [0.02],\n",
    "        \"confirm\": [0.02],\n",
    "        \"deny\": [0.02],\n",
    "    }\n",
    "    new_sentence_chances = [1, 0.95, 0.9, 0.85, 0.75, 0.5, 0.25, 0.1, 0]\n",
    "\n",
    "    # order content\n",
    "    sentence_count = 0\n",
    "    while random.random() < new_sentence_chances[min(sentence_count, len(new_sentence_chances) - 1)]:\n",
    "        conversation += randomize_oos()\n",
    "\n",
    "        # select intent with specified chances\n",
    "        selected_intent = ''\n",
    "        rand = random.random()\n",
    "        chance_counter = 0\n",
    "        for key, value in sentence_type_chances.items():\n",
    "            chance_counter += value[min(sentence_count, len(value) - 1)]\n",
    "            if rand < chance_counter:\n",
    "                selected_intent = key\n",
    "                break\n",
    "\n",
    "        if selected_intent == \"add_order_info\" or selected_intent == \"prompted_add_info\" or selected_intent == \"swap_order_info\" or selected_intent == \"delete_order_info\":\n",
    "            conversation += process_line(get_random_line(selected_intent), 'manage_order_info')\n",
    "        elif selected_intent == \"checkout\":\n",
    "            # randomize chance for only a single prompted name\n",
    "            rand = random.random()\n",
    "            if rand < 0.4:\n",
    "                conversation += process_line(get_random_line(\"prompted_name\"), 'manage_order_info')\n",
    "            elif rand < 0.8: \n",
    "                conversation += '|manage_order_info:NAME,0,0,0'\n",
    "        elif selected_intent == 'inquiry':\n",
    "            conversation += randomize_inquiry()\n",
    "        else:\n",
    "            conversation += process_line(get_random_line(selected_intent), selected_intent)\n",
    "\n",
    "        sentence_count += 1\n",
    "\n",
    "    return conversation\n",
    "\n",
    "def compile_conversations(output_file, total):\n",
    "    with open(output_file, \"w\") as file:\n",
    "        for i in range(total):\n",
    "            conversation = ''\n",
    "            guidedIntent = None\n",
    "\n",
    "            # greeting\n",
    "            conversation += randomize_greeting()\n",
    "\n",
    "            if \"order\" in conversation:\n",
    "                guidedIntent = 'order'\n",
    "            elif \"res\" in conversation:\n",
    "                guidedIntent = 'res'\n",
    "\n",
    "            if random.random() < 0.15:\n",
    "                conversation += compile_inquiry_sentences()\n",
    "\n",
    "                rand = random.random()\n",
    "                if rand < 0.4 or guidedIntent == 'order':\n",
    "                    conversation += compile_order_sentences()\n",
    "\n",
    "                    if random.random() < 0.05:\n",
    "                        conversation += compile_reservation_sentences()\n",
    "                elif rand < 0.4:\n",
    "                    conversation += compile_reservation_sentences()\n",
    "\n",
    "                    if random.random() < 0.05:\n",
    "                        conversation += compile_order_sentences()\n",
    "            else:\n",
    "                if random.random() < 0.5 or guidedIntent == 'res':\n",
    "                    conversation += compile_reservation_sentences()\n",
    "\n",
    "                    if random.random() < 0.05:\n",
    "                        conversation += compile_order_sentences()\n",
    "                else:\n",
    "                    conversation += compile_order_sentences()\n",
    "\n",
    "                    if random.random() < 0.05:\n",
    "                        conversation += compile_reservation_sentences()\n",
    "\n",
    "\n",
    "            # farewell\n",
    "            conversation += randomize_farewell()\n",
    "\n",
    "            # write conversation to file\n",
    "            file.write(conversation + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_conversations('./conversations.txt', 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Data Points\n",
    "\n",
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# environment variables\n",
    "sentence_memory = 2\n",
    "\n",
    "max_slot_length = 50\n",
    "slot_data_size = 6\n",
    "\n",
    "max_phantom_slot_length = 5\n",
    "phantom_slot_data_size = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_slot_map = {\n",
    "    \"[PAD]\": 0,\n",
    "    \"B-NAME\": 1,\n",
    "    \"I-NAME\": 2,\n",
    "    \"B-DATE\": 3,\n",
    "    \"I-DATE\": 4,\n",
    "    \"B-TIME\": 5,\n",
    "    \"I-TIME\": 6,\n",
    "    \"B-NUMBER\": 7,\n",
    "    \"I-NUMBER\": 8,\n",
    "    \"B-OBJECT\": 9,\n",
    "    \"I-OBJECT\": 10,\n",
    "    \"B-ALLERGEN\": 11,\n",
    "    \"I-ALLERGEN\": 12,\n",
    "    \"B-SIZE\": 13,\n",
    "    \"I-SIZE\": 14\n",
    "}\n",
    "\n",
    "intent_map = {\n",
    "    \"out_of_scope\": 0,\n",
    "    \"greeting\": 1,\n",
    "    \"farewell\": 2,\n",
    "    \"confirm\": 3,\n",
    "    \"deny\": 4,\n",
    "    \"allergy_declaration\": 5,\n",
    "\n",
    "    \"manage_order_info\": 6,\n",
    "    \"create_order\": 7,\n",
    "    \"access_prev_order\": 8,\n",
    "    \"cancel_order\": 9,\n",
    "    \"view_order\": 10,\n",
    "    \"checkout\": 11,\n",
    "\n",
    "    \"add_res_info\": 12,\n",
    "    \"view_res\": 13,\n",
    "    \"change_res_info\": 14,\n",
    "    \"cancel_res\": 15,\n",
    "\n",
    "    'allergen_inquiry': 16, \n",
    "    'basic_inquiry': 17, \n",
    "    'hours_inquiry': 18, \n",
    "    'language_inquiry': 19, \n",
    "    'location_inquiry': 20, \n",
    "    'manager_inquiry': 21, \n",
    "    'object_description_inquiry': 22, \n",
    "    'object_ingredient_inquiry': 23, \n",
    "    'object_nutritional_inquiry': 24, \n",
    "    'object_recommendation_inquiry': 25, \n",
    "    'order_queue_inquiry': 26, \n",
    "    'possible_object_inquiry': 27, \n",
    "    'possible_order_inquiry': 28, \n",
    "    'possible_reservation_inquiry': 29, \n",
    "    'price_inquiry': 30, \n",
    "    'profile_inquiry': 31, \n",
    "    'repeat_inquiry': 32, \n",
    "    'sms_inquiry': 33, \n",
    "    'software_inquiry': 34, \n",
    "    'table_queue_inquiry': 35, \n",
    "    'volume_inquiry': 36,\n",
    "\n",
    "    \"reference_prev_call\": 37,\n",
    "}\n",
    "\n",
    "entity_files = {\n",
    "    \"TIME\": \"../Filler_Data/time.txt\",\n",
    "    \"NAME\": \"../Filler_Data/names.txt\",\n",
    "    \"DATE\": \"../Filler_Data/date.txt\",\n",
    "    \"ITEM\": \"../Filler_Data/items.txt\",\n",
    "    \"NUMBER\": \"../Filler_Data/numbers.txt\",\n",
    "    \"ADDON\": \"../Filler_Data/addon.txt\",\n",
    "    \"SIZE\": \"../Filler_Data/size.txt\",\n",
    "    \"ALLERGEN\": \"../Filler_Data/allergen.txt\",\n",
    "}\n",
    "\n",
    "# Shared storage objects to store found arrays of sentences\n",
    "storage = {}\n",
    "storage_copy = {}\n",
    "\n",
    "for intent, file_path in entity_files.items():\n",
    "    with open(file_path, 'r') as file:\n",
    "        storage[intent] = [line.strip() for line in file.readlines() if line.strip() and not line.strip().startswith(\"//\")]\n",
    "\n",
    "storage_copy = copy.deepcopy(storage)\n",
    "\n",
    "def get_random_line(intent):\n",
    "    if len(storage[intent]) == 0:\n",
    "        storage[intent] = storage_copy[intent].copy()\n",
    "\n",
    "    selected_entity = random.choice(storage[intent]).strip()\n",
    "    storage[intent].remove(selected_entity)\n",
    "    return selected_entity\n",
    "\n",
    "def process_sentence(sentence):\n",
    "    # identify and encode intents\n",
    "    intents = [0] * len(intent_map)\n",
    "    for intent in (sentence.split(':')[0]).split(','):\n",
    "        intents[intent_map[intent]] = 1\n",
    "\n",
    "    # identify and fill slots\n",
    "    slot_type_map = []\n",
    "    slot_intent_map = []\n",
    "    slot_action_map = []\n",
    "    slot_pointers_map = []\n",
    "    sentence = sentence.split(':')[1]\n",
    "\n",
    "    # record and take out phantom slots\n",
    "    phantom_target_map = []\n",
    "    phantom_intent_map = []\n",
    "    phantom_action_map = []\n",
    "    phantom_pointers_map = []\n",
    "    if '*' in sentence:\n",
    "        phantom_slots = sentence.split('*')\n",
    "\n",
    "        for i in range(1, len(phantom_slots)):\n",
    "            processed_slot = phantom_slots[i].split(',')\n",
    "\n",
    "            phantom_target_map.append(int(processed_slot[0]))\n",
    "            phantom_intent_map.append(int(processed_slot[1]))\n",
    "            phantom_action_map.append(int(processed_slot[2]))\n",
    "            phantom_pointers_map.extend([int(x) for x in processed_slot][3:6] + [0] * (6 - len(processed_slot)))\n",
    "\n",
    "            sentence = sentence.replace(phantom_slots[i], '')\n",
    "\n",
    "        sentence = sentence.replace('*', '')\n",
    "\n",
    "    splitted = sentence.split(\" \")\n",
    "    for idx in range(len(splitted)):\n",
    "        # check for a slot\n",
    "        if ',' in splitted[idx]:\n",
    "            for placeholder, filepath in entity_files.items():\n",
    "                if placeholder in splitted[idx]:\n",
    "                    splitted[idx] = splitted[idx].replace('\\'s', '')\n",
    "                    splitted[idx] = splitted[idx].replace('s', '')\n",
    "                    processed_slot = splitted[idx].split(',')\n",
    "\n",
    "                    replacement = get_random_line(placeholder)\n",
    "                    if placeholder == 'NAME' and random.random() < 0.5: # assign two names on a 50% chance\n",
    "                        replacement += get_random_line(placeholder)\n",
    "\n",
    "                    # swap item and addon for object\n",
    "                    if placeholder == 'ITEM' or placeholder == 'ADDON':\n",
    "                        processed_slot[0] = 'OBJECT'\n",
    "\n",
    "                    # encode slot data\n",
    "                    slot_type_map.append(original_slot_map[\"B-\" + processed_slot[0]])\n",
    "                    slot_intent_map.append(int(processed_slot[1]))\n",
    "                    slot_action_map.append(int(processed_slot[2]))\n",
    "                    slot_pointers_map.extend([int(x) for x in processed_slot[3:6]] + [0] * (6 - len(processed_slot)))\n",
    "\n",
    "                    # add indices for number of words in replacement\n",
    "                    for i in range(len(tokenizer.tokenize(replacement)) - 1):\n",
    "                        # encode slot data\n",
    "                        slot_type_map.append(original_slot_map[\"I-\" + processed_slot[0]])\n",
    "                        slot_intent_map.append(int(processed_slot[1]))\n",
    "                        slot_action_map.append(int(processed_slot[2]))\n",
    "                        slot_pointers_map.extend([int(x) for x in processed_slot[3:6]] + [0] * (6 - len(processed_slot)))\n",
    "\n",
    "                    sentence = sentence.replace(splitted[idx], replacement, 1)\n",
    "                    break\n",
    "        else:\n",
    "            slot_type_map.append(0)\n",
    "            slot_intent_map.append(0)\n",
    "            slot_action_map.append(0)\n",
    "            slot_pointers_map.extend(3 * [0])\n",
    "\n",
    "    # pad slot data\n",
    "    slot_type_map += [0] * (max_slot_length - len(slot_type_map))\n",
    "    slot_intent_map += [0] * (max_slot_length - len(slot_intent_map))\n",
    "    slot_action_map += [0] * (max_slot_length - len(slot_action_map))\n",
    "    slot_pointers_map += [0] * ((max_slot_length - len(slot_pointers_map)) * 3)\n",
    "\n",
    "    # pad phantom slot data\n",
    "    phantom_target_map += [0] * (max_phantom_slot_length - len(phantom_target_map))\n",
    "    phantom_intent_map += [0] * (max_phantom_slot_length - len(phantom_intent_map))\n",
    "    phantom_action_map += [0] * (max_phantom_slot_length - len(phantom_action_map))\n",
    "    phantom_pointers_map += [0] * ((max_phantom_slot_length - len(phantom_pointers_map)) * 3)\n",
    "\n",
    "    # combine all slot data\n",
    "    slot_map = slot_type_map + slot_intent_map + slot_action_map + slot_pointers_map + phantom_target_map + phantom_intent_map + phantom_action_map + phantom_pointers_map\n",
    "\n",
    "    return sentence, intents, slot_map\n",
    "\n",
    "def process_conversation(conversation):\n",
    "    inputs = []\n",
    "    intentOutputs = []\n",
    "    slotOutputs = []\n",
    "    sentenceMemory = []\n",
    "\n",
    "    for sentence in conversation.split('|'):\n",
    "        if sentence != '':\n",
    "            processed_sentence, intents, slot_map = process_sentence(sentence)\n",
    "\n",
    "            # compile input\n",
    "            input = []\n",
    "            textInput = ''\n",
    "            for i in range(min(len(sentenceMemory), sentence_memory)):\n",
    "                textInput += sentenceMemory[i] + ' [SEP] '\n",
    "            textInput += processed_sentence\n",
    "\n",
    "            # Tokenize, extend, and pad the conversation\n",
    "            tokenized_text = tokenizer(textInput, padding='max_length', truncation=True, max_length=(max_slot_length * (sentence_memory + 1)))\n",
    "            input_ids = tokenized_text['input_ids']\n",
    "            input.extend(input_ids)\n",
    "\n",
    "            # extend and pad intents\n",
    "            input.extend([item for sublist in intentOutputs[-sentence_memory:] for item in sublist])\n",
    "            input += [0] * ((len(intent_map) * (sentence_memory)) + (max_slot_length * (sentence_memory + 1)) - len(input))\n",
    "\n",
    "            # extend and pad slots\n",
    "            input.extend([item for sublist in slotOutputs[-sentence_memory:] for item in sublist])\n",
    "            input += [0] * ((slot_data_size * max_slot_length + phantom_slot_data_size * max_phantom_slot_length) * (sentence_memory) + (((len(intent_map) * (sentence_memory)) + (max_slot_length * (sentence_memory + 1)) - len(input))))\n",
    "\n",
    "            if(len(input) != 886):\n",
    "                print(len(input))\n",
    "\n",
    "            # store input\n",
    "            inputs.append(input)\n",
    "\n",
    "            # store intents\n",
    "            intentOutputs.append(intents)\n",
    "\n",
    "            # pad slots\n",
    "            slot_map += [0] * (max_slot_length * slot_data_size + max_phantom_slot_length * phantom_slot_data_size - len(slot_map))\n",
    "\n",
    "            # store slots\n",
    "            slotOutputs.append(slot_map)\n",
    "\n",
    "            # store sentence\n",
    "            sentenceMemory.append(processed_sentence)\n",
    "    \n",
    "    return inputs, intentOutputs, slotOutputs\n",
    "\n",
    "def process_file(input_file, output_file):\n",
    "    inputs = []\n",
    "    intentOutputs = []\n",
    "    slotOutputs = []\n",
    "    \n",
    "    with open(input_file, 'r') as file:\n",
    "        conversations = [line.strip() for line in file.readlines()]\n",
    "\n",
    "    for conversation in conversations:\n",
    "        i, iO, sO = process_conversation(conversation)\n",
    "        inputs.extend(i)\n",
    "        intentOutputs.extend(iO)\n",
    "        slotOutputs.extend(sO)\n",
    "\n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump({\"inputs\": inputs, \"intentOutputs\": intentOutputs, \"slotOutputs\": slotOutputs}, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_file('./conversations.txt', './JERTmate_final_data.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
