{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JERTmate data processing\n",
    "\n",
    "Compile synthetic data and process into useable formats\n",
    "\n",
    "#### Basic definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TFBertModel\n\u001b[0;32m      9\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1551\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1550\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m-> 1551\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1550\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1550\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1551\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1560\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1559\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1560\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1561\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1562\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1563\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1564\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1565\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     TFBaseModelOutputWithPastAndCrossAttentions,\n\u001b[0;32m     31\u001b[0m     TFBaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     TFTokenClassifierOutput,\n\u001b[0;32m     39\u001b[0m )\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     41\u001b[0m     TFCausalLanguageModelingLoss,\n\u001b[0;32m     42\u001b[0m     TFMaskedLanguageModelingLoss,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m     unpack_inputs,\n\u001b[0;32m     54\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\activations_tf.py:22\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\__internal__\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\__internal__\\backend\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _initialize_variables \u001b[38;5;28;01mas\u001b[39;00m initialize_variables\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m track_variable\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\__init__.py:21\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the TF-Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\applications\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras Applications are premade architectures with pre-trained weights.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtBase\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtLarge\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtSmall\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\applications\\convnext.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\backend.py:33\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_config\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_coordinator_utils \u001b[38;5;28;01mas\u001b[39;00m dc\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtensor_api \u001b[38;5;28;01mas\u001b[39;00m dtensor\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1322\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1262\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1528\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1502\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1601\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFBertModel\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert = TFBertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 252 (3531711548.py, line 253)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 253\u001b[1;36m\u001b[0m\n\u001b[1;33m    elif selected_intent == 'cancel_order' or selected_intent == 'change_order_info' or selected_intent == 'order_status' or selected_intent == 'view_order':\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 252\n"
     ]
    }
   ],
   "source": [
    "sentence_files = {\n",
    "    # miscellaneous\n",
    "    \"greeting\": \"../Greeting_Farewell/greeting.txt\",\n",
    "    \"farewell\": \"../Greeting_Farewell/farewell.txt\",\n",
    "    \"out_of_scope\": \"../Out_of_Scope/out_of_scope.txt\",\n",
    "    \"prompted_name\": \"../Prompted_Name/prompted_name.txt\",\n",
    "    \"confirm\": \"../Confirm_Deny/confirm.txt\",\n",
    "    \"deny\": \"../Confirm_Deny/deny.txt\",\n",
    "\n",
    "    # reservation\n",
    "    \"cancel_res\": \"../Reservation/cancel_res.txt\",\n",
    "    \"view_res\": \"../Reservation/view_res.txt\",\n",
    "    \"order_status\": \"../Reservation/order_status.txt\",\n",
    "    \"change_res_info\": \"../Reservation/change_res_info.txt\",\n",
    "    \"add_res_info\": \"../Reservation/add_res_info.txt\",\n",
    "    \"prompted_res_inputs\": \"../Reservation/prompted_res_inputs.txt\",\n",
    "    \n",
    "    # order\n",
    "    \"add_order_info\": \"../Order/add_order_info.txt\",\n",
    "    \"change_order_info\": \"../Order/change_order_info.txt\",\n",
    "    \"view_order\": \"../Order/view_order.txt\",\n",
    "    \"cancel_order\": \"../Order/cancel_order.txt\",\n",
    "    \"checkout\": \"../Order/checkout.txt\",\n",
    "    \"prompted_order_inputs\": \"../Order/prompted_order_inputs.txt\",\n",
    "\n",
    "    # inquiry\n",
    "    \"menu_inquiry\": \"../Inquiry/menu_inquiry.txt\",\n",
    "    \"location_inquiry\": \"../Inquiry/location_inquiry.txt\",\n",
    "    \"hours_inquiry\": \"../Inquiry/hours_inquiry.txt\",\n",
    "}\n",
    "\n",
    "# Shared storage objects to store found arrays of sentences\n",
    "storage = {}\n",
    "storage_copy = {}\n",
    "with_strings_storage = {}\n",
    "without_strings_storage = {}\n",
    "\n",
    "for intent, file_path in sentence_files.items():\n",
    "    with open(file_path, 'r') as file:\n",
    "        storage[intent] = [line.strip() for line in file.readlines()]\n",
    "\n",
    "storage_copy = storage.copy()\n",
    "\n",
    "def get_random_line(intent):\n",
    "    if len(storage[intent]) == 0:\n",
    "        storage[intent] = storage_copy[intent]\n",
    "        \n",
    "    selected_entity = random.choice(storage[intent]).strip()\n",
    "    storage[intent].remove(selected_entity)\n",
    "    return selected_entity\n",
    "\n",
    "# select a random line that contains all strings in the strings array effectively\n",
    "def get_random_line_with_strings(intent, strings):\n",
    "    combo_key = tuple(sorted(strings))\n",
    "    \n",
    "    if combo_key not in with_strings_storage or len(with_strings_storage[combo_key]) == 0:\n",
    "        filtered_sentences = [sentence for sentence in storage_copy[intent] if all(string in sentence for string in strings)]\n",
    "        with_strings_storage[combo_key] = filtered_sentences\n",
    "    \n",
    "    if with_strings_storage[combo_key]:\n",
    "        selected_entity = random.choice(with_strings_storage[combo_key]).strip()\n",
    "        with_strings_storage[combo_key].remove(selected_entity)\n",
    "        return selected_entity\n",
    "    else:\n",
    "        raise ValueError(f\"No matching sentence found containing all strings: {strings}\")\n",
    "\n",
    "def get_random_line_without_strings(intent, strings):\n",
    "    combo_key = tuple(sorted(strings))\n",
    "    \n",
    "    if combo_key not in without_strings_storage or len(without_strings_storage[combo_key]) == 0:\n",
    "        filtered_sentences = [sentence for sentence in storage_copy[intent] if all(string not in sentence for string in strings)]\n",
    "        without_strings_storage[combo_key] = filtered_sentences\n",
    "    \n",
    "    if without_strings_storage[combo_key]:\n",
    "        selected_entity = random.choice(without_strings_storage[combo_key]).strip()\n",
    "        without_strings_storage[combo_key].remove(selected_entity)\n",
    "        return selected_entity\n",
    "    else:\n",
    "        raise ValueError(f\"No matching sentence found without any of the strings: {strings}\")\n",
    "\n",
    "def randomize_greeting():\n",
    "    if random.random() < 0.7:\n",
    "        return '|greeting:' + get_random_line(sentence_files[\"greeting\"])\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def randomize_farewell():\n",
    "    if random.random() < 0.7:\n",
    "        return '|farewell:' + get_random_line(sentence_files[\"farewell\"])\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def compile_reservation_sentences(output_file, num_reservation_sentences):\n",
    "    with open(output_file, \"w\") as file:\n",
    "        for i in range(num_reservation_sentences):\n",
    "            conversation = ''\n",
    "\n",
    "            # greeting\n",
    "            conversation += randomize_greeting()\n",
    "\n",
    "            # track provided entities\n",
    "            provided_entities = []\n",
    "            all_entities = [\"NAME\", \"TIME\", \"DATE\", \"NUMBER\"]\n",
    "\n",
    "            # define chances\n",
    "            sentence_type_chances = {\n",
    "                \"add_res_info\": [0.80],\n",
    "                \"cancel_res\": [0.03],\n",
    "                \"view_res\": [0.05],\n",
    "                \"change_res_info\": [0.06],\n",
    "\n",
    "                \"menu_inquiry\": [0.02],\n",
    "                \"hours_inquiry\": [0.02],\n",
    "                \"location_inquiry\": [0.01],\n",
    "\n",
    "                \"out_of_scope\": [0.01],\n",
    "            }\n",
    "\n",
    "            # order content\n",
    "            sentence_count = 0\n",
    "            while True:\n",
    "                # select intent with specified chances\n",
    "                selected_intent = ''\n",
    "                rand = random.random()\n",
    "                chance_counter = 0\n",
    "                for key, value in sentence_type_chances.items():\n",
    "                    chance_counter += value[min(sentence_count, len(value) - 1)]\n",
    "                    if rand < chance_counter:\n",
    "                        selected_intent = key\n",
    "                        break\n",
    "\n",
    "                # generate a sentences within specified intent\n",
    "                if sentence_count > 0 and (selected_intent == \"cancel_res\" or selected_intent == \"view_res\" or selected_intent == \"change_res\"):\n",
    "                    # if data has already been provided, we can only reference the res obj using that data\n",
    "                    unused_entities = [entity for entity in all_entities if entity not in provided_entities]\n",
    "                    conversation += '|' + selected_intent + \":\" + get_random_line_without_strings(selected_intent, unused_entities)\n",
    "                elif selected_intent == \"add_res_info\":\n",
    "                    # define possible entities\n",
    "                    possible_entities = [entity for entity in all_entities if entity not in provided_entities]\n",
    "\n",
    "                    # collect selected entities and the chances for more than one entity\n",
    "                    selected_entities = []\n",
    "                    extra_entity_chances = []\n",
    "\n",
    "                    # define different chances for more than one entity depending on intent\n",
    "                    if sentence_count == 0:\n",
    "                        extra_entity_chances = [1, 0.6, 0.2, 0.03]\n",
    "                    else:\n",
    "                        extra_entity_chances = [1, 0.25, 0.10, 0]\n",
    "\n",
    "                    for probability in extra_entity_chances:\n",
    "                        if random.random() < probability and len(possible_entities) > 0:\n",
    "                            #select a random entity and remove it from further possible choices\n",
    "                            selected_entity = random.choice(possible_entities)\n",
    "                            possible_entities.remove(selected_entity)\n",
    "\n",
    "                            selected_entities.append(selected_entity)\n",
    "\n",
    "                    # signal to the script which entities we are going to provide so they cannot be added again\n",
    "                    provided_entities.extend(selected_entities)\n",
    "\n",
    "                    # randomize the chance for a single inputted slot\n",
    "                    if selected_intent == \"add_res_info\" and len(selected_entities) == 1 and random.random() < 0.7:\n",
    "                        if random.random() < 0.5:\n",
    "                            conversation += '|add_res_info:' + selected_entities[0] + \",0,0\"\n",
    "                        else:\n",
    "                            conversation += '|add_res_info:' + get_random_line_with_strings(\"prompted_res_inputs\", selected_entities)\n",
    "                    else:\n",
    "                        conversation += '|' + selected_intent + \":\" + get_random_line_with_strings(selected_intent, selected_entities)\n",
    "\n",
    "                    # check if we have used all necessary entities\n",
    "                    if len(possible_entities) == 0:\n",
    "                        # simulate confirmation or denial\n",
    "                        while random.random() < 0.1:\n",
    "                            conversation += '|deny:' + get_random_line(sentence_files[\"deny\"])\n",
    "\n",
    "                            rand = random.random()\n",
    "                            if rand < 0.5:\n",
    "                                conversation += '|change_res_info:' + get_random_line(sentence_files[\"change_res_info\"])\n",
    "                            else:\n",
    "                                conversation += '|add_res_info:' + get_random_line(sentence_files[\"add_res_info\"])\n",
    "                        conversation += '|confirm:' + get_random_line(sentence_files[\"confirm\"])\n",
    "\n",
    "                    sentence_count += 1\n",
    "                else:\n",
    "                    conversation += '|' + selected_intent + \":\" + get_random_line(sentence_files[selected_intent])\n",
    "\n",
    "                # perform alterations based on intent and generated sentence\n",
    "                if selected_intent == \"cancel_res\" and random.random() < 0.35:\n",
    "                    break # end convo\n",
    "                elif selected_intent == \"cancel_res\":\n",
    "                    # reset conversation ticker\n",
    "                    sentence_count = 0\n",
    "\n",
    "            # farewell\n",
    "            conversation += randomize_farewell()\n",
    "\n",
    "            # write conversation to file\n",
    "            file.write(conversation + '\\n')\n",
    "\n",
    "def compile_order_sentences(output_file, num_order_sentences):\n",
    "    with open(output_file, \"w\") as file:\n",
    "        for i in range(num_order_sentences):\n",
    "            conversation = ''\n",
    "\n",
    "            # greeting\n",
    "            conversation += randomize_greeting()\n",
    "\n",
    "            # define chances\n",
    "            sentence_type_chances = {\n",
    "                \"add_order_info\": [0.8, 0.75, 0.7, 0.5, 0],\n",
    "                \"view_order\": [0.05, 0.05, 0.06, 0.06, 0],\n",
    "                \"cancel_order\": [0.04, 0.04, 0.03, 0.03, 0.14],\n",
    "                \"change_order_info\": [0.05, 0.05, 0.05, 0.05, 0],\n",
    "                \"checkout\": [0, 0.5, 0.1, 0.3, 0.85],\n",
    "\n",
    "                \"order_status\": [],\n",
    "                \"menu_inquiry\": [0.02, 0.02, 0.02, 0.02, 0],\n",
    "                \"hours_inquiry\": [0.02, 0.02, 0.02, 0.02, 0],\n",
    "                \"location_inquiry\": [0.01, 0.01, 0.01, 0.01, 0],\n",
    "\n",
    "                \"out_of_scope\": [0.01],\n",
    "            }\n",
    "\n",
    "            # order content\n",
    "            sentence_count = 0\n",
    "            cart = {}\n",
    "            slot_count = 0\n",
    "            while True:\n",
    "                # select intent with specified chances\n",
    "                selected_intent = ''\n",
    "                rand = random.random()\n",
    "                chance_counter = 0\n",
    "                for key, value in sentence_type_chances.items():\n",
    "                    chance_counter += value[min(sentence_count, len(value) - 1)]\n",
    "                    if rand < chance_counter:\n",
    "                        selected_intent = key\n",
    "                        break\n",
    "\n",
    "                if selected_intent == 'add_order_info':\n",
    "                    sentence_count += 1\n",
    "                    sentence = ''\n",
    "\n",
    "                    if sentence_count > 0 and random.random() < 0.5:\n",
    "                        sentence = get_random_line(sentence_files[\"prompted_order_inputs\"])\n",
    "                        conversation += '|add_order_info:' + sentence\n",
    "                    else:\n",
    "                        sentence = get_random_line(sentence_files[selected_intent])\n",
    "                        conversation += '|' + selected_intent + \":\" + sentence\n",
    "\n",
    "                    # update cart\n",
    "                    slots = re.findall(r'\\*?(?:PREV_)?[A-Z]+,\\d+,\\d+', sentence)\n",
    "                    for i in range(slots):\n",
    "                        slot_count += 1\n",
    "                        split = slots[i].split(',')\n",
    "\n",
    "                        parent = None\n",
    "                        grandparent = None\n",
    "                        if slots[int(split[2])] is not None:\n",
    "                            parent = slots[int(split[2])]\n",
    "                            parent_split = parent.split(',')\n",
    "                            if slots[int(parent_split[2])] is not None:\n",
    "                                grandparent = slots[int(parent_split[2])]\n",
    "                                grandparent_split = grandparent.split(',')\n",
    "\n",
    "                                if cart[slot_count + int(grandparent_split[2])] is None:\n",
    "                                    cart[slot_count + int(grandparent_split[2])] = ['', {}]\n",
    "\n",
    "                            if cart[slot_count + int(parent_split[2])] is None:\n",
    "                                cart[slot_count + int(parent_split[2])] = ['', []]\n",
    "\n",
    "                        if parent is None:\n",
    "                            cart[slot_count + i + 1] = [slots[i], {}]\n",
    "                        if grandparent is None:\n",
    "                            cart[slot_count + int(parent_split[2])][1][slot_count + i + 1] = [slots[i], {}]\n",
    "                        else:\n",
    "                            cart[slot_count + int(parent_split[2])][1][slot_count + int(grandparent_split[2])][1].append(slots[i])\n",
    "                elif selected_intent == 'cancel_order' or selected_intent == 'change_order_info' or selected_intent == 'order_status' or selected_intent == 'view_order':\n",
    "                    if sentence_count > 0 and random.random() < 0.9: # follow PREV_ guidelines\n",
    "                        # find a randomized line that fits the conversation\n",
    "                        possible_lines = []\n",
    "                        for line in storage[selected_intent]:\n",
    "                            necessary_items = {}\n",
    "                            slots = re.findall(r'\\*?PREV_[A-Z_]+,\\d+,\\d+', line)\n",
    "                            for i in range(slots):\n",
    "                                split = slots[i].split(',')\n",
    "\n",
    "                                parent = None\n",
    "                                grandparent = None\n",
    "                                if slots[int(split[2])] is not None:\n",
    "                                    parent = slots[int(split[2])]\n",
    "                                    parent_split = parent.split(',')\n",
    "                                    if slots[int(parent_split[2])] is not None:\n",
    "                                        grandparent = slots[int(parent_split[2])]\n",
    "                                        grandparent_split = grandparent.split(',')\n",
    "\n",
    "                                        if necessary_items[int(grandparent_split[2])] is None:\n",
    "                                            necessary_items[int(grandparent_split[2])] = ['', {}]\n",
    "\n",
    "                                    if necessary_items[int(parent_split[2])] is None:\n",
    "                                        necessary_items[int(parent_split[2])] = ['', {}]\n",
    "\n",
    "                                if parent is None:\n",
    "                                    necessary_items[i + 1] = [split[0], {}]\n",
    "                                if grandparent is None:\n",
    "                                    necessary_items[int(parent_split[2])][1][slot_count + i + 1] = [split[0], {}]\n",
    "                                else:\n",
    "                                    necessary_items[int(parent_split[2])][1][int(grandparent_split[2])][1].append(split[0])\n",
    "\n",
    "                            possible_parent_positions = []\n",
    "                            for key1, necessary_item_grandparent in necessary_items.items():\n",
    "                                possible_parent_positions.append({})\n",
    "                                for key2, cart_grandparent in cart.items():\n",
    "                                    if necessary_item_grandparent[0] == cart_grandparent[0]:\n",
    "                                        if len(necessary_item_grandparent[1]) == 0:\n",
    "                                            possible_parent_positions[-1][key1] = key2\n",
    "                                        else:\n",
    "                                            for key3, necessary_item_parent in necessary_item_grandparent[1]:\n",
    "                                                for key4, cart_parent in cart_grandparent[1]:\n",
    "                                                    if necessary_item_parent[0] == cart_parent[0]:\n",
    "                                                        if len(necessary_item_parent[1]) == 0:\n",
    "                                                            if possible_parent_positions[-1][key1] is None:\n",
    "                                                                possible_parent_positions[-1][key1] = key2\n",
    "                                                            possible_parent_positions[-1][key3] = key4\n",
    "                                                        else:\n",
    "                                                            for necessary_item_child in necessary_item_parent[1]:\n",
    "                                                                for cart_child in cart_parent[1]:\n",
    "                                                                    if possible_parent_positions[-1][key1] is None:\n",
    "                                                                        possible_parent_positions[-1][key1] = key2\n",
    "                                                                    if possible_parent_positions[-1][key3] is None:\n",
    "                                                                        possible_parent_positions[-1][key3] = key4\n",
    "                                                                    possible_parent_positions[-1][necessary_item_child] = cart_child\n",
    "                                \n",
    "                                if len(possible_parent_positions[-1]) != 0:\n",
    "                                    possible_lines.append(line)\n",
    "\n",
    "                        sentence = random.choice(possible_lines).strip()\n",
    "                        #!find the corresponding possible parent positions\n",
    "                        possible_parent_positions = {}\n",
    "\n",
    "                        # set correct parent relationships\n",
    "\n",
    "\n",
    "                        # update cart\n",
    "                        # delete items\n",
    "\n",
    "                        # add items\n",
    "\n",
    "                    else: # eliminate PREV_ all together\n",
    "                        sentence = get_random_line(sentence_files[selected_intent])\n",
    "                        conversation += '|' + selected_intent + \":\" + sentence.replace('PREV_', '')\n",
    "                else:\n",
    "                    conversation += '|' + selected_intent + \":\" + get_random_line(sentence_files[selected_intent])\n",
    "\n",
    "                if (selected_intent == \"cancel_order\" and random.random() < 0.5) or selected_intent == \"checkout\":\n",
    "\n",
    "                    #simulate confirmation or denial\n",
    "                    if selected_intent == \"checkout\":\n",
    "                        if not re.search(r\"make_order:[^|]*\\bNAME\\b\", conversation): # check if the user has already inputted their name\n",
    "                            # randomize chance for only a single prompted name\n",
    "                            if random.random() < 0.5:\n",
    "                                conversation += '|add_order_info:' + get_random_line(sentence_files[\"prompted_name\"])\n",
    "                            else: \n",
    "                                conversation += '|add_order_info:NAME,0,0'\n",
    "\n",
    "                        while random.random() < 0.1:\n",
    "                            conversation += '|deny:' + get_random_line(sentence_files[\"deny\"])\n",
    "\n",
    "                            rand = random.random()\n",
    "                            if rand < 0.5:\n",
    "                                conversation += '|change_order_info:' + get_random_line(sentence_files[\"change_order_info\"])\n",
    "                            else:\n",
    "                                conversation += '|add_order_info:' + get_random_line(sentence_files[\"add_order_info\"])\n",
    "                        conversation += '|confirm:' + get_random_line(sentence_files[\"confirm\"])\n",
    "\n",
    "                        if random.random() < 0.03:\n",
    "                            conversation += '|order_status:' + get_random_line(sentence_files[\"order_status\"])\n",
    "\n",
    "                    break # end convo\n",
    "                elif selected_intent == \"cancel_order\":\n",
    "                    # reset conversation ticker\n",
    "                    sentence_count = 0\n",
    "\n",
    "            # farewell\n",
    "            conversation += randomize_farewell()\n",
    "\n",
    "            # write conversation to file\n",
    "            file.write(conversation + '\\n')\n",
    "\n",
    "def compile_inquiry_sentences(output_file, num_inquiry_sentences):\n",
    "    with open(output_file, \"w\") as file:\n",
    "        for i in range(num_inquiry_sentences):\n",
    "            conversation = ''\n",
    "\n",
    "            # greeting\n",
    "            conversation += randomize_greeting()\n",
    "\n",
    "            # define chances\n",
    "            sentence_type_chances = {\n",
    "                \"out_of_scope\": [0.05],\n",
    "                \"menu_inquiry\": [0.25],\n",
    "                \"order_status\": [0.25],\n",
    "            }\n",
    "            new_sentence_chances = [1, 0.25, 0]\n",
    "\n",
    "            # order content\n",
    "            sentence_count = 0\n",
    "            while random.random() < new_sentence_chances[min(sentence_count, len(new_sentence_chances) - 1)]:\n",
    "                rand = random.random()\n",
    "                chance_counter = 0\n",
    "                for key, value in sentence_type_chances.items():\n",
    "                    chance_counter += value[min(sentence_count, len(value) - 1)]\n",
    "                    if rand < chance_counter:\n",
    "                        conversation += '|' + key + \":\" + get_random_line(sentence_files[key])\n",
    "\n",
    "                sentence_count += 1\n",
    "\n",
    "            # farewell\n",
    "            conversation += randomize_farewell()\n",
    "\n",
    "            # write conversation to file\n",
    "            file.write(conversation + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PREV_SOMETHING_RANDOM,8,3']\n"
     ]
    }
   ],
   "source": [
    "#compile_reservation_sentences(\"../Reservation/res_conversations.txt\", 10000)\n",
    "#compile_order_sentences(\"../Order/order_conversations.txt\", 10000)\n",
    "#compile_inquiry_sentences(\"../Inquiry/inquiry_conversations.txt\", 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Created Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_slot_map = {\n",
    "    \"[PAD]\": 0,\n",
    "    \"B-NAME\": 1,\n",
    "    \"I-NAME\": 2,\n",
    "    \"B-DATE\": 3,\n",
    "    \"I-DATE\": 4,\n",
    "    \"B-TIME\": 5,\n",
    "    \"I-TIME\": 6,\n",
    "    \"B-NUMBER\": 7,\n",
    "    \"I-NUMBER\": 8,\n",
    "    \"B-ITEM\": 9,\n",
    "    \"I-ITEM\": 10,\n",
    "    \"B_DRINK\": 11,\n",
    "    \"I_DRINK\": 12,\n",
    "    \"B-ADDON\": 13,\n",
    "    \"I-ADDON\": 14,\n",
    "    \"B-SIZE\": 15,\n",
    "    \"I-SIZE\": 16\n",
    "}\n",
    "\n",
    "intent_map = {\n",
    "    \"out_of_scope\": 0,\n",
    "    \"greeting\": 1,\n",
    "    \"farewell\": 2,\n",
    "    \"view_res\": 3,\n",
    "    \"add_res_info\": 4,\n",
    "    \"change_res_info\": 5,\n",
    "    \"cancel_res\": 6,\n",
    "    \"add_order_info\": 7,\n",
    "    \"change_order_info\": 8,\n",
    "    \"view_order\": 9,\n",
    "    \"cancel_order\": 10,\n",
    "    \"checkout\": 11,\n",
    "    \"menu_inquiry\": 12,\n",
    "    \"location_inquiry\": 13,\n",
    "    \"hours_inquiry\": 14\n",
    "}\n",
    "\n",
    "entity_files = {\n",
    "    \"DRINK_ADDON\": \"../Filler_Data/drink_addon.txt\",\n",
    "    \"ADDON_SIZE\": \"../Filler_Data/addon_size.txt\",\n",
    "    \"TIME\": \"../Filler_Data/times.txt\",\n",
    "    \"NAME\": \"../Filler_Data/names.txt\",\n",
    "    \"DATE\": \"../Filler_Data/dates.txt\",\n",
    "    \"ITEM\": \"../Filler_Data/food_items.txt\",\n",
    "    \"NUMBER\": \"../Filler_Data/numbers.txt\",\n",
    "    \"ADDON\": \"../Filler_Data/addon.txt\",\n",
    "    \"SIZE\": \"../Filler_Data/size.txt\",\n",
    "    \"DRINK\": \"../Filler_Data/drink_items.txt\",\n",
    "}\n",
    "\n",
    "def process_sentence(sentence, entity_files):\n",
    "    # isolate intent\n",
    "    intent = intent_map[sentence.split(':')[0]]\n",
    "    sentence = sentence.split(':')[1]\n",
    "\n",
    "    slot_map = []\n",
    "    slot_memory = {\n",
    "        \"NAME\": None,\n",
    "        \"ORDER\": [],\n",
    "        \"DATE\": None,\n",
    "        \"TIME\": None,\n",
    "        \"NUMBER\": None,\n",
    "    }\n",
    "    splitted = sentence.split()\n",
    "\n",
    "    for idx in range(len(splitted)):\n",
    "        is_slot = False\n",
    "        # check if its a phantom slot\n",
    "        if not splitted[idx].includes('*'):\n",
    "            for placeholder, filepath in entity_files.items():\n",
    "                if placeholder in splitted[idx]:\n",
    "                    is_slot = True\n",
    "                    processed_slot = splitted[idx].split(',')\n",
    "\n",
    "                    replacement = None\n",
    "                    if processed_slot[0].includes('PREV'):\n",
    "                        processed_slot[0].replace('PREV_', '')\n",
    "\n",
    "                        if slot_memory[placeholder] is not None:\n",
    "                            replacement = slot_memory[placeholder]\n",
    "\n",
    "                        #! How can we do this for cart items? -> simply check for parent and fill with parent filler\n",
    "                    \n",
    "                    if replacement is None:\n",
    "                        replacement = get_random_line(filepath)\n",
    "                        if placeholder == 'NAME' and random.random() < 0.5: # assign two names on a 50% chance\n",
    "                            replacement += \" \" + get_random_line(filepath)\n",
    "\n",
    "\n",
    "\n",
    "                    # swap slot for drink_addon and addon_size\n",
    "                    if placeholder == 'DRINK_ADDON':\n",
    "                        processed_slot[0] = 'ADDON'\n",
    "                    elif placeholder == 'ADDON_SIZE':\n",
    "                        processed_slot[0] = 'SIZE'\n",
    "\n",
    "                    slot_map.append([original_slot_map[\"B-\" + processed_slot[0]], int(processed_slot[1]), int(processed_slot[2])])\n",
    "\n",
    "                    # add indices for number of words in replacement\n",
    "                    for i in range(len(replacement.split()) - 1):\n",
    "                        slot_map.append([original_slot_map[\"I-\" + processed_slot[0]], int(processed_slot[1]), int(processed_slot[2])])\n",
    "\n",
    "                    # \n",
    "\n",
    "                    sentence = re.sub(r'[A-Z_]+,\\d+,\\d+', replacement, sentence, count=1)\n",
    "                    break\n",
    "        else: # it's a phantom slot\n",
    "            is_slot = True\n",
    "            processed_slot = splitted[idx].split(',')\n",
    "\n",
    "            slot_map.append([original_slot_map[\"B-\" + processed_slot[0].replace('*', '')], int(processed_slot[1]), int(processed_slot[2])])\n",
    "\n",
    "        if not is_slot:\n",
    "            slot_map.append([0,0,0])\n",
    "\n",
    "    return sentence, intent, slot_map\n",
    "\n",
    "def process_conversation(conversation, entity_files):\n",
    "    data = []\n",
    "    memory = []\n",
    "\n",
    "    for sentence in conversation.split('|'):\n",
    "        processed_sentence, intent, slot_map = process_sentence(sentence, entity_files)\n",
    "\n",
    "        data.append({\n",
    "            \"text\": processed_sentence,\n",
    "            \"intent\": intent,\n",
    "            \"slots\": slot_map,\n",
    "            \"memory\": memory.copy()\n",
    "        })\n",
    "\n",
    "        memory.append({\n",
    "            \"text\": processed_sentence,\n",
    "            \"intent\": intent,\n",
    "            \"slots\": slot_map\n",
    "        })\n",
    "    \n",
    "    return data\n",
    "\n",
    "def process_file(input_file, output_file, entity_files):\n",
    "    data = []\n",
    "    with open(input_file, 'r') as file:\n",
    "        conversations = [line.strip() for line in file.readlines()]\n",
    "\n",
    "    for conversation in conversations:\n",
    "        data.extend(process_conversation(conversation, entity_files))\n",
    "\n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprocess_conversation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madd_res_info:confirm booking details for NUMBER,0,0 visitor party coming on DATE,0,0|view_res:what time is my reservation this DATE,0,0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_files\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[4], line 89\u001b[0m, in \u001b[0;36mprocess_conversation\u001b[1;34m(conversation, entity_files)\u001b[0m\n\u001b[0;32m     86\u001b[0m memory \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m conversation\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 89\u001b[0m     processed_sentence, intent, slot_map \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: processed_sentence,\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintent\u001b[39m\u001b[38;5;124m\"\u001b[39m: intent,\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslots\u001b[39m\u001b[38;5;124m\"\u001b[39m: slot_map,\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory\u001b[39m\u001b[38;5;124m\"\u001b[39m: memory\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     96\u001b[0m     })\n\u001b[0;32m     98\u001b[0m     memory\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: processed_sentence,\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintent\u001b[39m\u001b[38;5;124m\"\u001b[39m: intent,\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslots\u001b[39m\u001b[38;5;124m\"\u001b[39m: slot_map\n\u001b[0;32m    102\u001b[0m     })\n",
      "Cell \u001b[1;32mIn[4], line 66\u001b[0m, in \u001b[0;36mprocess_sentence\u001b[1;34m(sentence, entity_files)\u001b[0m\n\u001b[0;32m     63\u001b[0m is_slot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     64\u001b[0m processed_slot \u001b[38;5;241m=\u001b[39m splitted[idx]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 66\u001b[0m replacement \u001b[38;5;241m=\u001b[39m \u001b[43mget_random_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m placeholder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNAME\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.5\u001b[39m: \u001b[38;5;66;03m# assign two names on a 50% chance\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     replacement \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m get_random_line(filepath)\n",
      "Cell \u001b[1;32mIn[3], line 34\u001b[0m, in \u001b[0;36mget_random_line\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     33\u001b[0m     lines \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom\u001b[49m\u001b[38;5;241m.\u001b[39mchoice(lines)\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "print(process_conversation(\"add_res_info:confirm booking details for NUMBER,0,0 visitor party coming on DATE,0,0|view_res:what time is my reservation this DATE,0,0\", entity_files))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
