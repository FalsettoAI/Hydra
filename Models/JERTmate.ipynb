{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint Bert Model for slot and intent classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/14 09:38:51 INFO mlflow.utils.credentials: Successfully connected to MLflow hosted tracking server! Host: https://636605817503717.7.gcp.databricks.com.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from transformers import TFBertModel\n",
    "from transformers import AutoTokenizer\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten, Reshape, Conv1D\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy, BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy, CategoricalAccuracy, BinaryAccuracy\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "# connect MLFlow\n",
    "import mlflow\n",
    "mlflow.login()\n",
    "\n",
    "# set the experiment id\n",
    "mlflow.set_experiment(experiment_id=\"939972677444421\")\n",
    "\n",
    "mlflow.enable_system_metrics_logging()\n",
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "intentOutputs = []\n",
    "slotOutputs = []\n",
    "\n",
    "with open(\"../processing/JERTmate_final_data.json\", \"r\", encoding=\"utf-8\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "    inputs = data[\"inputs\"]\n",
    "    intentOutputs = data[\"intentOutputs\"]\n",
    "    slotOutputs = data[\"slotOutputs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data - Train 80% | Validation 10% | Test 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_arrays(inputs, intentOutputs, slotOutputs, train_ratio, val_ratio, test_ratio):\n",
    "    assert len(inputs) == len(intentOutputs) == len(slotOutputs), \"All arrays must have the same length\"\n",
    "    \n",
    "    n_total = len(inputs)\n",
    "    n_train = int(n_total * train_ratio)\n",
    "    n_val = int(n_total * val_ratio)\n",
    "    \n",
    "    # split inputs\n",
    "    inputs_train, inputs_val, inputs_test = inputs[:n_train], inputs[n_train:n_train + n_val], inputs[n_train + n_val:]\n",
    "\n",
    "    # split intents\n",
    "    intentOutputs_train, intentOutputs_val, intentOutputs_test = intentOutputs[:n_train], intentOutputs[n_train:n_train + n_val], intentOutputs[n_train + n_val:]\n",
    "\n",
    "    # split slots\n",
    "    slot_type_map_train, slot_type_map_val, slot_type_map_test = [x[:50] for x in slotOutputs[:n_train]], [x[:50] for x in slotOutputs[n_train:n_train + n_val]], [x[:50] for x in slotOutputs[n_train + n_val:]]\n",
    "    slot_intent_map_train, slot_intent_map_val, slot_intent_map_test = [x[50:100] for x in slotOutputs[:n_train]], [x[50:100] for x in slotOutputs[n_train:n_train + n_val]], [x[50:100] for x in slotOutputs[n_train + n_val:]]\n",
    "    slot_action_map_train, slot_action_map_val, slot_action_map_test = [x[100:150] for x in slotOutputs[:n_train]], [x[100:150] for x in slotOutputs[n_train:n_train + n_val]], [x[100:150] for x in slotOutputs[n_train + n_val:]]\n",
    "    slot_pointers_map_train, slot_pointers_map_val, slot_pointers_map_test = [x[150:300] for x in slotOutputs[:n_train]], [x[150:300] for x in slotOutputs[n_train:n_train + n_val]], [x[150:300] for x in slotOutputs[n_train + n_val:]]\n",
    "    phantom_target_map_train, phantom_target_map_val, phantom_target_map_test = [x[300:305] for x in slotOutputs[:n_train]], [x[300:305] for x in slotOutputs[n_train:n_train + n_val]], [x[300:305] for x in slotOutputs[n_train + n_val:]]\n",
    "    phantom_intent_map_train, phantom_intent_map_val, phantom_intent_map_test = [x[305:310] for x in slotOutputs[:n_train]], [x[305:310] for x in slotOutputs[n_train:n_train + n_val]], [x[305:310] for x in slotOutputs[n_train + n_val:]]\n",
    "    phantom_action_map_train, phantom_action_map_val, phantom_action_map_test = [x[310:315] for x in slotOutputs[:n_train]], [x[310:315] for x in slotOutputs[n_train:n_train + n_val]], [x[310:315] for x in slotOutputs[n_train + n_val:]]\n",
    "    phantom_pointers_map_train, phantom_pointers_map_val, phantom_pointers_map_test = [x[315:] for x in slotOutputs[:n_train]], [x[315:] for x in slotOutputs[n_train:n_train + n_val]], [x[315:] for x in slotOutputs[n_train + n_val:]]\n",
    "\n",
    "    \n",
    "    return (tf.constant(inputs_train), tf.constant(inputs_val), tf.constant(inputs_test)), (tf.constant(intentOutputs_train), tf.constant(intentOutputs_val), tf.constant(intentOutputs_test)), (tf.constant(slot_type_map_train), tf.constant(slot_type_map_val), tf.constant(slot_type_map_test)), (tf.constant(slot_intent_map_train), tf.constant(slot_intent_map_val), tf.constant(slot_intent_map_test)), (tf.constant(slot_action_map_train), tf.constant(slot_action_map_val), tf.constant(slot_action_map_test)), (tf.constant(slot_pointers_map_train), tf.constant(slot_pointers_map_val), tf.constant(slot_pointers_map_test)), (tf.constant(phantom_target_map_train), tf.constant(phantom_target_map_val), tf.constant(phantom_target_map_test)), (tf.constant(phantom_intent_map_train), tf.constant(phantom_intent_map_val), tf.constant(phantom_intent_map_test)), (tf.constant(phantom_action_map_train), tf.constant(phantom_action_map_val), tf.constant(phantom_action_map_test)), (tf.constant(phantom_pointers_map_train), tf.constant(phantom_pointers_map_val), tf.constant(phantom_pointers_map_test))\n",
    "\n",
    "\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "(inputs_train, inputs_val, inputs_test), (intentOutputs_train, intentOutputs_val, intentOutputs_test), (slot_type_map_train, slot_type_map_val, slot_type_map_test), (slot_intent_map_train, slot_intent_map_val, slot_intent_map_test), (slot_action_map_train, slot_action_map_val, slot_action_map_test), (slot_pointers_map_train, slot_pointers_map_val, slot_pointers_map_test), (phantom_target_map_train, phantom_target_map_val, phantom_target_map_test), (phantom_intent_map_train, phantom_intent_map_val, phantom_intent_map_test), (phantom_action_map_train, phantom_action_map_val, phantom_action_map_test), (phantom_pointers_map_train, phantom_pointers_map_val, phantom_pointers_map_test) = split_arrays(inputs, intentOutputs, slotOutputs, train_ratio, val_ratio, test_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "class JointIntentAndSlotFillingModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, intent_vector_length=None, total_slot_number=None, total_phantom_slot_number=None, slot_types=None, slot_intents=None, pointer_possibilities=None, model_name=model_name, dropout_prob=0.05):\n",
    "        super().__init__(name=\"joint_intent_slot\")\n",
    "        #   ** GENERAL LAYERS **\n",
    "        self.bert = TFBertModel.from_pretrained(model_name) # BERT model\n",
    "        self.dropout = Dropout(dropout_prob) # basic dropout layer\n",
    "        self.flatten = Flatten() # flatten layer\n",
    "\n",
    "\n",
    "\n",
    "        #   ** SLOT LAYERS **\n",
    "        # LHS compressor\n",
    "        self.LHSC_conv1 = Conv1D(filters=256, kernel_size=1, activation='relu', padding='same', name='LHSC_conv1')\n",
    "        self.LHSC_conv2 = Conv1D(filters=64, kernel_size=1, activation='relu', padding='same', name='LHSC_conv2')\n",
    "        self.LHSC_conv3 = Conv1D(filters=32, kernel_size=1, activation='relu', padding='same', name='LHSC_conv3')\n",
    "\n",
    "        # slot output layers\n",
    "        self.slot_type_dense = Dense(total_slot_number * slot_types, activation='softmax', name=\"slot_type_output\")\n",
    "        self.slot_type_reshape = Reshape((total_slot_number, slot_types))\n",
    "        \n",
    "        self.slot_intent_dense = Dense(total_slot_number * slot_intents, activation='softmax', name=\"slot_intent_output\")\n",
    "        self.slot_intent_reshape = Reshape((total_slot_number, slot_intents))\n",
    "        \n",
    "        self.slot_action_output = Dense(total_slot_number, activation='sigmoid', name=\"slot_action_output\")\n",
    "        \n",
    "        self.slot_pointers_dense = Dense(total_slot_number * pointer_possibilities * 3, activation='softmax', name=\"slot_pointers_output\")\n",
    "        self.slot_pointers_reshape = Reshape((total_slot_number * 3, pointer_possibilities))\n",
    "\n",
    "        # Phantom slot output layers\n",
    "        self.phantom_slot_target_dense = Dense(total_phantom_slot_number * pointer_possibilities, activation='softmax', name=\"phantom_slot_target_output\")\n",
    "        self.phantom_slot_target_reshape = Reshape((total_phantom_slot_number, pointer_possibilities))\n",
    "        \n",
    "        self.phantom_slot_intent_dense = Dense(total_phantom_slot_number * slot_intents, activation='softmax', name=\"phantom_slot_intent_output\")\n",
    "        self.phantom_slot_intent_reshape = Reshape((total_phantom_slot_number, slot_intents))\n",
    "        \n",
    "        self.phantom_slot_action_output = Dense(total_phantom_slot_number, activation='sigmoid', name=\"phantom_slot_action_output\")\n",
    "        \n",
    "        self.phantom_slot_pointers_dense = Dense(total_phantom_slot_number * pointer_possibilities * 3, activation='softmax', name=\"phantom_slot_pointers_output\")\n",
    "        self.phantom_slot_pointers_reshape = Reshape((total_phantom_slot_number * 3, pointer_possibilities))\n",
    "\n",
    "\n",
    "\n",
    "        #  ** INTENT LAYERS **\n",
    "        # processing layers\n",
    "        self.intent_processor_one = Dense(294, activation=\"relu\", name=\"intent_processor_one\")\n",
    "        self.intent_processor_two = Dense(147, activation=\"relu\", name=\"intent_processor_two\")\n",
    "\n",
    "        # output layer\n",
    "        self.intent_output = Dense(intent_vector_length, activation='softmax', name=\"intent_output\")\n",
    "\n",
    "        # Build the model with input shape (None, 886)\n",
    "        self.build(input_shape=(None, 886))\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        bertInputs = inputs[:, :150]\n",
    "\n",
    "        # run BERT\n",
    "        trained_bert = self.bert(bertInputs, **kwargs)\n",
    "        pooled_output = trained_bert.pooler_output\n",
    "        sequence_output = trained_bert.last_hidden_state\n",
    "\n",
    "        #   ** SLOT CLASSIFICATION **\n",
    "        # use CNN to compress the sequence output\n",
    "        conv_output = self.LHSC_conv1(sequence_output)\n",
    "        conv_output = self.LHSC_conv2(conv_output)\n",
    "        conv_output = self.LHSC_conv3(conv_output)\n",
    "\n",
    "        # flatten the compressed output\n",
    "        flattened_LHSC_output = self.flatten(conv_output)\n",
    "\n",
    "        # slot output\n",
    "        slot_output_input = self.dropout(tf.concat([flattened_LHSC_output, tf.cast(inputs[:, 150:], dtype=tf.float32)], axis=-1), training=kwargs.get(\"training\", False))\n",
    "        \n",
    "        slot_type_output = self.slot_type_dense(slot_output_input)\n",
    "        slot_type_output = self.slot_type_reshape(slot_type_output)\n",
    "        \n",
    "        slot_intent_output = self.slot_intent_dense(slot_output_input)\n",
    "        slot_intent_output = self.slot_intent_reshape(slot_intent_output)\n",
    "        \n",
    "        slot_action_output = self.slot_action_output(slot_output_input)\n",
    "        \n",
    "        slot_pointers_output = self.slot_pointers_dense(slot_output_input)\n",
    "        slot_pointers_output = self.slot_pointers_reshape(slot_pointers_output)\n",
    "\n",
    "        # Phantom slot outputs\n",
    "        phantom_target_output = self.phantom_slot_target_dense(slot_output_input)\n",
    "        phantom_target_output = self.phantom_slot_target_reshape(phantom_target_output)\n",
    "        \n",
    "        phantom_intent_output = self.phantom_slot_intent_dense(slot_output_input)\n",
    "        phantom_intent_output = self.phantom_slot_intent_reshape(phantom_intent_output)\n",
    "        \n",
    "        phantom_action_output = self.phantom_slot_action_output(slot_output_input)\n",
    "        \n",
    "        phantom_pointers_output = self.phantom_slot_pointers_dense(slot_output_input)\n",
    "        phantom_pointers_output = self.phantom_slot_pointers_reshape(phantom_pointers_output)\n",
    "\n",
    "\n",
    "\n",
    "        #   ** INTENT CLASSIFICATION **\n",
    "        # intent processor\n",
    "        intent_processor_one_input = self.dropout(tf.concat([pooled_output, tf.cast(inputs[:, 150:150 + 114], dtype=tf.float32)], axis=-1), training=kwargs.get(\"training\", False))\n",
    "        intent_processor_one = self.intent_processor_one(intent_processor_one_input)\n",
    "\n",
    "        intent_processor_two_input = self.dropout(intent_processor_one, training=kwargs.get(\"training\", False))\n",
    "        intent_processor_two = self.intent_processor_two(intent_processor_two_input)\n",
    "\n",
    "        # intent output\n",
    "        intent_output_input = self.dropout(intent_processor_two, training=kwargs.get(\"training\", False))\n",
    "        intent_output = self.intent_output(intent_output_input)\n",
    "\n",
    "        # Return outputs as a dictionary\n",
    "        return {\n",
    "            \"intent\": intent_output,\n",
    "            \"slot_type\": slot_type_output,\n",
    "            \"slot_intent\": slot_intent_output,\n",
    "            \"slot_action\": slot_action_output,\n",
    "            \"slot_pointers\": slot_pointers_output,\n",
    "            \"phantom_slot_target\": phantom_target_output,\n",
    "            \"phantom_slot_intent\": phantom_intent_output,\n",
    "            \"phantom_slot_action\": phantom_action_output,\n",
    "            \"phantom_slot_pointers\": phantom_pointers_output\n",
    "        }\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(JointIntentAndSlotFillingModel, self).get_config()\n",
    "        return config\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "    \n",
    "joint_model = JointIntentAndSlotFillingModel(intent_vector_length=38, total_slot_number=50, total_phantom_slot_number=5, slot_types=15, slot_intents=4, pointer_possibilities=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/14 09:39:06 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "2024/10/14 09:39:06 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '830678b04d5748d0bde2a1db7cbfb17b', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n",
      "2024/10/14 09:39:06 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: If 'features' is a TensorFlow Tensor, then 'targets' must also be a TensorFlow Tensor. Found: <class 'dict'>.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1741/1741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - intent_intent_accuracy: 0.2927 - loss: 16.9208 - phantom_slot_action_phantom_slot_action_accuracy: 0.8288 - phantom_slot_intent_phantom_slot_intent_accuracy: 0.8496 - phantom_slot_pointers_phantom_slot_pointer_accuracy: 0.7958 - phantom_slot_target_phantom_slot_target_accuracy: 0.8068 - slot_action_slot_action_accuracy: 0.8530 - slot_intent_slot_intent_accuracy: 0.8241 - slot_pointers_slot_pointer_accuracy: 0.7438 - slot_type_slot_type_accuracy: 0.6875\n",
      "Epoch 1: saving model to model_epoch_01.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1741/1741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5376s\u001b[0m 3s/step - intent_intent_accuracy: 0.2928 - loss: 16.9203 - phantom_slot_action_phantom_slot_action_accuracy: 0.8289 - phantom_slot_intent_phantom_slot_intent_accuracy: 0.8497 - phantom_slot_pointers_phantom_slot_pointer_accuracy: 0.7959 - phantom_slot_target_phantom_slot_target_accuracy: 0.8069 - slot_action_slot_action_accuracy: 0.8530 - slot_intent_slot_intent_accuracy: 0.8241 - slot_pointers_slot_pointer_accuracy: 0.7439 - slot_type_slot_type_accuracy: 0.6876 - val_intent_intent_accuracy: 0.5504 - val_loss: 15.3658 - val_phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - val_phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - val_phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - val_phantom_slot_target_phantom_slot_target_accuracy: 0.9999 - val_slot_action_slot_action_accuracy: 0.9806 - val_slot_intent_slot_intent_accuracy: 0.9889 - val_slot_pointers_slot_pointer_accuracy: 0.9923 - val_slot_type_slot_type_accuracy: 0.9094 - learning_rate: 5.6031e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m1741/1741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - intent_intent_accuracy: 0.5563 - loss: 15.2618 - phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - slot_action_slot_action_accuracy: 0.9806 - slot_intent_slot_intent_accuracy: 0.9889 - slot_pointers_slot_pointer_accuracy: 0.9922 - slot_type_slot_type_accuracy: 0.9088\n",
      "Epoch 2: saving model to model_epoch_02.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1741/1741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5298s\u001b[0m 3s/step - intent_intent_accuracy: 0.5563 - loss: 15.2618 - phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - slot_action_slot_action_accuracy: 0.9806 - slot_intent_slot_intent_accuracy: 0.9889 - slot_pointers_slot_pointer_accuracy: 0.9922 - slot_type_slot_type_accuracy: 0.9088 - val_intent_intent_accuracy: 0.5744 - val_loss: 15.0484 - val_phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - val_phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - val_phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - val_phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - val_slot_action_slot_action_accuracy: 0.9806 - val_slot_intent_slot_intent_accuracy: 0.9889 - val_slot_pointers_slot_pointer_accuracy: 0.9923 - val_slot_type_slot_type_accuracy: 0.9060 - learning_rate: 9.9987e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m1741/1741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - intent_intent_accuracy: 0.5759 - loss: 15.0561 - phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - slot_action_slot_action_accuracy: 0.9801 - slot_intent_slot_intent_accuracy: 0.9887 - slot_pointers_slot_pointer_accuracy: 0.9922 - slot_type_slot_type_accuracy: 0.9045\n",
      "Epoch 3: saving model to model_epoch_03.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1741/1741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5257s\u001b[0m 3s/step - intent_intent_accuracy: 0.5759 - loss: 15.0561 - phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - slot_action_slot_action_accuracy: 0.9801 - slot_intent_slot_intent_accuracy: 0.9887 - slot_pointers_slot_pointer_accuracy: 0.9922 - slot_type_slot_type_accuracy: 0.9045 - val_intent_intent_accuracy: 0.5890 - val_loss: 15.0234 - val_phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - val_phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - val_phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - val_phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - val_slot_action_slot_action_accuracy: 0.9803 - val_slot_intent_slot_intent_accuracy: 0.9888 - val_slot_pointers_slot_pointer_accuracy: 0.9921 - val_slot_type_slot_type_accuracy: 0.9020 - learning_rate: 9.9553e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m1741/1741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - intent_intent_accuracy: 0.5726 - loss: 15.1601 - phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - slot_action_slot_action_accuracy: 0.9804 - slot_intent_slot_intent_accuracy: 0.9885 - slot_pointers_slot_pointer_accuracy: 0.9918 - slot_type_slot_type_accuracy: 0.8998\n",
      "Epoch 4: saving model to model_epoch_04.keras\n",
      "\u001b[1m1741/1741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5229s\u001b[0m 3s/step - intent_intent_accuracy: 0.5726 - loss: 15.1602 - phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - slot_action_slot_action_accuracy: 0.9804 - slot_intent_slot_intent_accuracy: 0.9885 - slot_pointers_slot_pointer_accuracy: 0.9918 - slot_type_slot_type_accuracy: 0.8998 - val_intent_intent_accuracy: 0.2979 - val_loss: 16.7649 - val_phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - val_phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - val_phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - val_phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - val_slot_action_slot_action_accuracy: 0.9796 - val_slot_intent_slot_intent_accuracy: 0.9887 - val_slot_pointers_slot_pointer_accuracy: 0.9920 - val_slot_type_slot_type_accuracy: 0.9015 - learning_rate: 9.8503e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m1741/1741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - intent_intent_accuracy: 0.5426 - loss: 15.6683 - phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - slot_action_slot_action_accuracy: 0.9811 - slot_intent_slot_intent_accuracy: 0.9888 - slot_pointers_slot_pointer_accuracy: 0.9917 - slot_type_slot_type_accuracy: 0.8982\n",
      "Epoch 5: saving model to model_epoch_05.keras\n",
      "\u001b[1m1741/1741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5193s\u001b[0m 3s/step - intent_intent_accuracy: 0.5426 - loss: 15.6683 - phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - slot_action_slot_action_accuracy: 0.9811 - slot_intent_slot_intent_accuracy: 0.9888 - slot_pointers_slot_pointer_accuracy: 0.9917 - slot_type_slot_type_accuracy: 0.8982 - val_intent_intent_accuracy: 0.5059 - val_loss: 17.7746 - val_phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - val_phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - val_phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - val_phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - val_slot_action_slot_action_accuracy: 0.9809 - val_slot_intent_slot_intent_accuracy: 0.9888 - val_slot_pointers_slot_pointer_accuracy: 0.9914 - val_slot_type_slot_type_accuracy: 0.8888 - learning_rate: 9.6851e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m1741/1741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - intent_intent_accuracy: 0.5223 - loss: 16.5364 - phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - slot_action_slot_action_accuracy: 0.9808 - slot_intent_slot_intent_accuracy: 0.9884 - slot_pointers_slot_pointer_accuracy: 0.9916 - slot_type_slot_type_accuracy: 0.8926\n",
      "Epoch 6: saving model to model_epoch_06.keras\n",
      "\u001b[1m1741/1741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5178s\u001b[0m 3s/step - intent_intent_accuracy: 0.5223 - loss: 16.5366 - phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - slot_action_slot_action_accuracy: 0.9808 - slot_intent_slot_intent_accuracy: 0.9884 - slot_pointers_slot_pointer_accuracy: 0.9916 - slot_type_slot_type_accuracy: 0.8926 - val_intent_intent_accuracy: 0.3317 - val_loss: 21.9857 - val_phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - val_phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - val_phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - val_phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - val_slot_action_slot_action_accuracy: 0.9810 - val_slot_intent_slot_intent_accuracy: 0.9888 - val_slot_pointers_slot_pointer_accuracy: 0.9915 - val_slot_type_slot_type_accuracy: 0.8905 - learning_rate: 9.4618e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m1741/1741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - intent_intent_accuracy: 0.4951 - loss: 18.0265 - phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - slot_action_slot_action_accuracy: 0.9820 - slot_intent_slot_intent_accuracy: 0.9886 - slot_pointers_slot_pointer_accuracy: 0.9910 - slot_type_slot_type_accuracy: 0.8854\n",
      "Epoch 7: saving model to model_epoch_07.keras\n",
      "\u001b[1m1741/1741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5170s\u001b[0m 3s/step - intent_intent_accuracy: 0.4951 - loss: 18.0269 - phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - slot_action_slot_action_accuracy: 0.9820 - slot_intent_slot_intent_accuracy: 0.9886 - slot_pointers_slot_pointer_accuracy: 0.9910 - slot_type_slot_type_accuracy: 0.8854 - val_intent_intent_accuracy: 0.4106 - val_loss: 20.3856 - val_phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - val_phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - val_phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - val_phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - val_slot_action_slot_action_accuracy: 0.9814 - val_slot_intent_slot_intent_accuracy: 0.9889 - val_slot_pointers_slot_pointer_accuracy: 0.9921 - val_slot_type_slot_type_accuracy: 0.8928 - learning_rate: 9.1830e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m1741/1741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - intent_intent_accuracy: 0.4719 - loss: 20.8013 - phantom_slot_action_phantom_slot_action_accuracy: 1.0000 - phantom_slot_intent_phantom_slot_intent_accuracy: 1.0000 - phantom_slot_pointers_phantom_slot_pointer_accuracy: 1.0000 - phantom_slot_target_phantom_slot_target_accuracy: 1.0000 - slot_action_slot_action_accuracy: 0.9822 - slot_intent_slot_intent_accuracy: 0.9889 - slot_pointers_slot_pointer_accuracy: 0.9921 - slot_type_slot_type_accuracy: 0.8965"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/14 21:22:37 INFO mlflow.tracking._tracking_service.client: 🏃 View run redolent-hen-104 at: https://636605817503717.7.gcp.databricks.com/ml/experiments/939972677444421/runs/830678b04d5748d0bde2a1db7cbfb17b.\n",
      "2024/10/14 21:22:37 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://636605817503717.7.gcp.databricks.com/ml/experiments/939972677444421.\n",
      "2024/10/14 21:22:37 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/10/14 21:22:38 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "This optimizer was created with a `LearningRateSchedule` object as its `learning_rate` constructor argument, hence its learning rate is not settable. If you need the learning rate to be settable, you should instantiate the optimizer with a float `learning_rate` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 92\u001b[0m\n\u001b[0;32m     89\u001b[0m joint_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mopt, loss\u001b[38;5;241m=\u001b[39mlosses, loss_weights\u001b[38;5;241m=\u001b[39mloss_weights, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# train!\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mjoint_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintent_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mintentOutputs_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mslot_type_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mslot_type_map_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mslot_intent_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mslot_intent_map_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mslot_action_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mslot_action_map_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mslot_pointers_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mslot_pointers_map_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphantom_slot_target_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mphantom_target_map_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphantom_slot_intent_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mphantom_intent_map_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphantom_slot_action_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mphantom_action_map_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphantom_slot_pointers_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mphantom_pointers_map_train\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintent_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mintentOutputs_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mslot_type_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mslot_type_map_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mslot_intent_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mslot_intent_map_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mslot_action_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mslot_action_map_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mslot_pointers_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mslot_pointers_map_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphantom_slot_target_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mphantom_target_map_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphantom_slot_intent_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mphantom_intent_map_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphantom_slot_action_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mphantom_action_map_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphantom_slot_pointers_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mphantom_pointers_map_val\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:578\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m try_log_autologging_event(\n\u001b[0;32m    569\u001b[0m     AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_patch_function_start,\n\u001b[0;32m    570\u001b[0m     session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    574\u001b[0m     kwargs,\n\u001b[0;32m    575\u001b[0m )\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m patch_is_class:\n\u001b[1;32m--> 578\u001b[0m     \u001b[43mpatch_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    580\u001b[0m     patch_function(call_original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:165\u001b[0m, in \u001b[0;36mPatchFunction.call\u001b[1;34m(cls, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mcls\u001b[39m, original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:176\u001b[0m, in \u001b[0;36mPatchFunction.__call__\u001b[1;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_exception(e)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# Regardless of what happens during the `_on_exception` callback, reraise\u001b[39;00m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;66;03m# the original implementation exception once the callback completes\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:169\u001b[0m, in \u001b[0;36mPatchFunction.__call__\u001b[1;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_patch_implementation\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:227\u001b[0m, in \u001b[0;36mwith_managed_run.<locals>.PatchWithManagedRun._patch_implementation\u001b[1;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mactive_run():\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanaged_run \u001b[38;5;241m=\u001b[39m create_managed_run()\n\u001b[1;32m--> 227\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_patch_implementation\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanaged_run:\n\u001b[0;32m    230\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mend_run(RunStatus\u001b[38;5;241m.\u001b[39mto_string(RunStatus\u001b[38;5;241m.\u001b[39mFINISHED))\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\tensorflow\\__init__.py:1352\u001b[0m, in \u001b[0;36mautolog.<locals>.FitPatch._patch_implementation\u001b[1;34m(self, original, inst, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1346\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m   1347\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to log training dataset information to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1348\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLflow Tracking. Reason: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1349\u001b[0m             e,\n\u001b[0;32m   1350\u001b[0m         )\n\u001b[1;32m-> 1352\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m log_models:\n\u001b[0;32m   1355\u001b[0m     _log_keras_model(history, args)\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:561\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[1;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m         original_result \u001b[38;5;241m=\u001b[39m original(\u001b[38;5;241m*\u001b[39m_og_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_og_kwargs)\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[1;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_original_fn_with_event_logging\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_original_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:496\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[1;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     try_log_autologging_event(\n\u001b[0;32m    489\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_start,\n\u001b[0;32m    490\u001b[0m         session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    494\u001b[0m         og_kwargs,\n\u001b[0;32m    495\u001b[0m     )\n\u001b[1;32m--> 496\u001b[0m     original_fn_result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    498\u001b[0m     try_log_autologging_event(\n\u001b[0;32m    499\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_success,\n\u001b[0;32m    500\u001b[0m         session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    504\u001b[0m         og_kwargs,\n\u001b[0;32m    505\u001b[0m     )\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:558\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[1;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;66;03m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[0;32m    555\u001b[0m     disable_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    556\u001b[0m     reroute_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    557\u001b[0m ):\n\u001b[1;32m--> 558\u001b[0m     original_result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_og_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_og_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\falkt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:530\u001b[0m, in \u001b[0;36mBaseOptimizer.learning_rate\u001b[1;34m(self, learning_rate)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    528\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learning_rate, learning_rate_schedule\u001b[38;5;241m.\u001b[39mLearningRateSchedule\n\u001b[0;32m    529\u001b[0m     ):\n\u001b[1;32m--> 530\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    531\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis optimizer was created with a `LearningRateSchedule`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    532\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m object as its `learning_rate` constructor argument, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhence its learning rate is not settable. If you need the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m learning rate to be settable, you should instantiate \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe optimizer with a float `learning_rate` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    536\u001b[0m         )\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learning_rate\u001b[38;5;241m.\u001b[39massign(learning_rate)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prev_lr_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learning_rate, backend\u001b[38;5;241m.\u001b[39mVariable\n\u001b[0;32m    540\u001b[0m ):\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;66;03m# Untrack learning rate variable\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: This optimizer was created with a `LearningRateSchedule` object as its `learning_rate` constructor argument, hence its learning rate is not settable. If you need the learning rate to be settable, you should instantiate the optimizer with a float `learning_rate` argument."
     ]
    }
   ],
   "source": [
    "# Define a learning rate schedule (e.g., cosine decay)\n",
    "total_steps = epochs * (len(inputs_train) / batch_size)\n",
    "warmup_steps = total_steps * 0.1\n",
    "lr_schedule = CosineDecay(\n",
    "    initial_learning_rate=1e-7,\n",
    "    decay_steps=total_steps - warmup_steps,\n",
    "    name='CosineDecay',\n",
    "    warmup_target=5e-5,\n",
    "    warmup_steps=warmup_steps\n",
    ")\n",
    "\n",
    "# optimizer\n",
    "opt = AdamW(learning_rate=lr_schedule, weight_decay=3e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "\n",
    "# Model checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=\"model_epoch_{epoch:02d}.keras\",  # Save the model with the epoch number in the filename\n",
    "    save_freq='epoch',\n",
    "    save_weights_only=False,\n",
    "    verbose=1 \n",
    ")\n",
    "\n",
    "# loss functions\n",
    "losses = {\n",
    "    \"intent\": CategoricalCrossentropy(name=\"intent_loss\"), \n",
    "    \"slot_type\": SparseCategoricalCrossentropy(from_logits=True, name=\"slot_type_loss\"),\n",
    "    \"slot_intent\": SparseCategoricalCrossentropy(from_logits=True, name=\"slot_intent_loss\"),\n",
    "    \"slot_action\": BinaryCrossentropy(name=\"slot_actionable_loss\"), \n",
    "    \"slot_pointers\": SparseCategoricalCrossentropy(from_logits=True, name=\"slot_pointer_loss\"),\n",
    "    \"phantom_slot_target\": SparseCategoricalCrossentropy(from_logits=True, name=\"phantom_slot_target_loss\"),\n",
    "    \"phantom_slot_intent\": SparseCategoricalCrossentropy(from_logits=True, name=\"phantom_slot_intent_loss\"),\n",
    "    \"phantom_slot_action\": BinaryCrossentropy(name=\"phantom_slot_actionable_loss\"), \n",
    "    \"phantom_slot_pointers\": SparseCategoricalCrossentropy(from_logits=True, name=\"phantom_slot_pointer_loss\"),\n",
    "}\n",
    "\n",
    "# loss weights\n",
    "loss_weights = {\n",
    "    \"intent\": 1.5,\n",
    "    \"slot_type\": 1.0,\n",
    "    \"slot_intent\": 1.0,\n",
    "    \"slot_action\": 0.6,\n",
    "    \"slot_pointers\": 1.0,\n",
    "    \"phantom_slot_target\": 0.8,\n",
    "    \"phantom_slot_intent\": 0.8,\n",
    "    \"phantom_slot_action\": 0.6,\n",
    "    \"phantom_slot_pointers\": 0.8,\n",
    "}\n",
    "\n",
    "# metrics\n",
    "metrics = {\n",
    "    \"intent\": [\n",
    "        CategoricalAccuracy(name=\"intent_accuracy\"), \n",
    "    ],\n",
    "    \"slot_type\": [\n",
    "        SparseCategoricalAccuracy(name=\"slot_type_accuracy\"), \n",
    "    ],\n",
    "    \"slot_intent\": [\n",
    "        SparseCategoricalAccuracy(name=\"slot_intent_accuracy\"), \n",
    "    ],\n",
    "    \"slot_action\": [\n",
    "        BinaryAccuracy(name=\"slot_action_accuracy\"), \n",
    "    ],\n",
    "    \"slot_pointers\": [\n",
    "        SparseCategoricalAccuracy(name=\"slot_pointer_accuracy\"), \n",
    "    ],\n",
    "    \"phantom_slot_target\": [\n",
    "        SparseCategoricalAccuracy(name=\"phantom_slot_target_accuracy\"), \n",
    "    ],\n",
    "    \"phantom_slot_intent\": [\n",
    "        SparseCategoricalAccuracy(name=\"phantom_slot_intent_accuracy\"), \n",
    "    ],\n",
    "    \"phantom_slot_action\": [\n",
    "        BinaryAccuracy(name=\"phantom_slot_action_accuracy\"), \n",
    "    ],\n",
    "    \"phantom_slot_pointers\": [\n",
    "        SparseCategoricalAccuracy(name=\"phantom_slot_pointer_accuracy\"), \n",
    "    ]\n",
    "}\n",
    "\n",
    "# compile model\n",
    "joint_model.compile(optimizer=opt, loss=losses, loss_weights=loss_weights, metrics=metrics)\n",
    "\n",
    "# train!\n",
    "history = joint_model.fit(\n",
    "    x=inputs_train,\n",
    "    y={\n",
    "        \"intent_output\": intentOutputs_train,\n",
    "        \"slot_type_output\": slot_type_map_train,\n",
    "        \"slot_intent_output\": slot_intent_map_train,\n",
    "        \"slot_action_output\": slot_action_map_train,\n",
    "        \"slot_pointers_output\": slot_pointers_map_train,\n",
    "        \"phantom_slot_target_output\": phantom_target_map_train,\n",
    "        \"phantom_slot_intent_output\": phantom_intent_map_train,\n",
    "        \"phantom_slot_action_output\": phantom_action_map_train,\n",
    "        \"phantom_slot_pointers_output\": phantom_pointers_map_train\n",
    "    }, \n",
    "    validation_data=(\n",
    "        inputs_val,\n",
    "        {\n",
    "            \"intent_output\": intentOutputs_val,\n",
    "            \"slot_type_output\": slot_type_map_val,\n",
    "            \"slot_intent_output\": slot_intent_map_val,\n",
    "            \"slot_action_output\": slot_action_map_val,\n",
    "            \"slot_pointers_output\": slot_pointers_map_val,\n",
    "            \"phantom_slot_target_output\": phantom_target_map_val,\n",
    "            \"phantom_slot_intent_output\": phantom_intent_map_val,\n",
    "            \"phantom_slot_action_output\": phantom_action_map_val,\n",
    "            \"phantom_slot_pointers_output\": phantom_pointers_map_val\n",
    "        }\n",
    "    ),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model\n",
    "\n",
    "keep in mind -> test slot accuracy will be higher than reality.\n",
    "        Because 90% of the data points are 0, it can just guess 0 and be right 85% of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_intent_acc, test_slot_type, test_slot_intent, test_slot_action, test_slot_pointers, test_phantom_target, test_phantom_intent, test_phantom_action, test_phantom_pointers = joint_model.evaluate(x=inputs_test, y=(intentOutputs_test, slot_type_map_test, slot_intent_map_test, slot_action_map_test, slot_pointers_map_test, phantom_target_map_test, phantom_intent_map_test, phantom_action_map_test, phantom_pointers_map_test), batch_size=batch_size)\n",
    "\n",
    "print(f\"Test Intent Accuracy: {test_intent_acc}\")\n",
    "print(f\"Test Slot Type Accuracy: {test_slot_type}\")\n",
    "print(f\"Test Slot Intent Accuracy: {test_slot_intent}\")\n",
    "print(f\"Test Slot Action Accuracy: {test_slot_action}\")\n",
    "print(f\"Test Slot Pointers Accuracy: {test_slot_pointers}\")\n",
    "print(f\"Test Phantom Target Accuracy: {test_phantom_target}\")\n",
    "print(f\"Test Phantom Intent Accuracy: {test_phantom_intent}\")\n",
    "print(f\"Test Phantom Action Accuracy: {test_phantom_action}\")\n",
    "print(f\"Test Phantom Pointers Accuracy: {test_phantom_pointers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def inferConversation(conversation):\n",
    "    conversation = conversation.split(\"|\")\n",
    "    memory = []\n",
    "    for i in range(len(conversation)):\n",
    "        textInput = ''\n",
    "        for i in range(max(i - 2, 0), i):\n",
    "            textInput += conversation[i] + ' [SEP] '\n",
    "        textInput += conversation[i]\n",
    "    \n",
    "        output = inferSentence(textInput, memory)\n",
    "\n",
    "        # update memory\n",
    "        if len(memory) > 2:\n",
    "            memory.pop(0)    \n",
    "        memory.append(output)\n",
    "\n",
    "def inferSentence(sentence, memory):\n",
    "    # tokenize\n",
    "    input = tokenizer(sentence, return_tensors=\"tf\", padding=\"max_length\", max_length=150, truncation=True)\n",
    "\n",
    "    # compile memory\n",
    "    intentMemory = []\n",
    "    slotMemory = []\n",
    "    for key in input:\n",
    "        intentMemory.extend(key[\"intent_output\"])\n",
    "        slotMemory.extend([key[\"slot_type_output\"], key[\"slot_intent_output\"], key[\"slot_action_output\"], key[\"slot_pointers_output\"], key[\"phantom_slot_target_output\"], key[\"phantom_slot_intent_output\"], key[\"phantom_slot_action_output\"], key[\"phantom_slot_pointers_output\"]])\n",
    "\n",
    "    input.extend(intentMemory)\n",
    "    input.extend(slotMemory)\n",
    "\n",
    "    input = memory.extend(input)\n",
    "\n",
    "    # predict\n",
    "    output = joint_model.predict(input)\n",
    "\n",
    "    return output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
